{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 08:50:55.138561: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-16 08:50:55.138598: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from prepared_data.get_prepared_data import get_prepared_data\n",
    "from prepared_data.train_model import split_features_target_and_map_target, save_results, callbacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load and prepard data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrzej/PycharmProjects/Physionet_Challenge_2021/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3251: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent of object with nan value and orginals:  0.00, 92.767131\n"
     ]
    },
    {
     "data": {
      "text/plain": "['target',\n 'home_team_history_match_date_1',\n 'home_team_history_is_play_home_1',\n 'home_team_history_is_cup_1',\n 'home_team_history_goal_1',\n 'home_team_history_opponent_goal_1',\n 'home_team_history_rating_1',\n 'home_team_history_opponent_rating_1',\n 'home_team_history_coach_1',\n 'away_team_history_match_date_1',\n 'away_team_history_is_play_home_1',\n 'away_team_history_is_cup_1',\n 'away_team_history_goal_1',\n 'away_team_history_opponent_goal_1',\n 'away_team_history_rating_1',\n 'away_team_history_opponent_rating_1',\n 'away_team_history_coach_1',\n 'home_team_history_gol_difference_1',\n 'home_team_mean_regeneration_time',\n 'away_team_history_gol_difference_1',\n 'away_team_mean_regeneration_time',\n 'home_team_mean_hist_rat',\n 'home_team_mean_all_ratting',\n 'away_team_mean_hist_rat',\n 'away_team_mean_all_ratting',\n 'league_id_ratting',\n 'sum_history_targets',\n 'home_team_history_target_1_-1.0',\n 'home_team_history_target_1_0.0',\n 'away_team_history_target_1_-1.0',\n 'away_team_history_target_1_0.0']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_org = pd.read_csv('data/train.csv')\n",
    "train, _, _ = get_prepared_data(train_org, map_target=False, number_of_history_matches=4)\n",
    "train = pd.read_csv('data/train_made.csv', index_col=0)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classify function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def build_and_compile_model(shape, n_neurons, dropout, learning_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(\n",
    "            n_neurons, activation='relu',\n",
    "            input_shape=shape),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find model parameters and save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent of object with nan value and orginals:  0.00, 92.767131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:47:36.366292: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-06 23:47:36.366320: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-06 23:47:36.366337: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Zenon): /proc/driver/nvidia/version does not exist\n",
      "2022-05-06 23:47:36.366528: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: early stopping\n",
      "Epoch 00011: early stopping\n",
      "Epoch 00015: early stopping\n",
      "Epoch 00011: early stopping\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import operator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "train, _, _ = get_prepared_data(train_org, map_target=False, number_of_history_matches=4)\n",
    "\n",
    "for dropout in range(5, 6):\n",
    "\n",
    "    dropout = 0.3\n",
    "    n_neurons = 16\n",
    "    learning_rate = 0.001\n",
    "    batch_size = None\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    train_features, target = split_features_target_and_map_target(train)\n",
    "\n",
    "    dnn_model = build_and_compile_model((train_features.shape[-1],), n_neurons, dropout, learning_rate)\n",
    "\n",
    "    model_name = f'final/{4}_MinMax_{n_neurons}_d_{dropout}_{n_neurons}' + datetime.now().strftime(\"%Y:%m:%d-%H:%M:%S\")\n",
    "    output_path = 'evaluate_results/' + model_name\n",
    "\n",
    "    save_results(output_path, f'lr={learning_rate} batch={batch_size}', dnn_model.summary)\n",
    "\n",
    "    i = 0\n",
    "    max_value_val_acc = list(range(0, 5))\n",
    "    min_value_val_loss = list(range(0, 5))\n",
    "    train_acc = list(range(0, 5))\n",
    "    train_loss = list(range(0, 5))\n",
    "\n",
    "    for train_index, test_index in StratifiedKFold(n_splits=5, shuffle=True, random_state=33).split(train_features,\n",
    "                                                                                                    target):\n",
    "        train_features_fold = scaler.fit_transform(train_features.iloc[train_index])\n",
    "        val_features_fold = scaler.transform(train_features.iloc[test_index])\n",
    "\n",
    "        model_full_name = model_name + f'/folds_{i}'\n",
    "\n",
    "        early_stop, reduce_lr, tensorboard_callback, checkpoint_callback = callbacks(model_full_name)\n",
    "\n",
    "        history = dnn_model.fit(\n",
    "            train_features_fold,\n",
    "            target.iloc[train_index],\n",
    "            validation_data=(val_features_fold, target.iloc[test_index]),\n",
    "            verbose=0, epochs=50,\n",
    "            callbacks=[early_stop, reduce_lr, checkpoint_callback, tensorboard_callback],\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        max_index_val_acc, max_value_val_acc[i] = max(enumerate(history.history['val_accuracy'], ),\n",
    "                                                      key=operator.itemgetter(1))\n",
    "        train_acc[i] = history.history['accuracy'][max_index_val_acc]\n",
    "\n",
    "        min_index_val_loss, min_value_val_loss[i] = min(enumerate(history.history['val_loss'], ),\n",
    "                                                        key=operator.itemgetter(1))\n",
    "        train_loss[i] = history.history['loss'][min_index_val_loss]\n",
    "\n",
    "        out_string = f'f_{i}\\nval_acc={max_value_val_acc[i]} train_acc={train_acc[i]} ep={max_index_val_acc + 1}\\nval_loss={min_value_val_loss[i]} train_loss={train_loss[i]} ep={min_index_val_loss + 1}'\n",
    "\n",
    "        save_results(output_path, out_string)\n",
    "        i += 1\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        dnn_model = build_and_compile_model((train_features.shape[-1],), n_neurons, dropout, learning_rate)\n",
    "\n",
    "        # dnn_model = build_and_compile_model(normalizer,n_neurons,dropout,learning_rate)\n",
    "\n",
    "    out_string = f'median\\nval_acc={np.median(max_value_val_acc)} train_acc={np.median(train_acc)}\\nval_loss={np.median(min_value_val_loss)} train_loss={np.median(train_loss)}'\n",
    "\n",
    "    save_results(output_path, out_string)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}